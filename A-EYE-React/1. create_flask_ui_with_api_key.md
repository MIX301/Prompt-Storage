# Create Flask UI with API key
_Exported on 15/11/2025 at 4:50:11 CET from Cursor (1.7.44)_

---

**User**

Create a Flask UI around this and use the secret "GOOGLE_API_KEY" from my .env file. 

---

**Cursor**

Reviewing the existing code and configuration to understand what we're working with.


Creating a Flask UI around the existing code. Building the Flask app, templates, and updating dependencies.


Creating a Flask UI with WebSocket support for real-time audio/video streaming. Building the Flask app and templates:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import pyaudio
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

pya = pyaudio.PyAudio()

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        def send_async():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(audio_loop.send_text_message(text))
        
        thread = Thread(target=send_async, daemon=True)
        thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)

```

Fixing the import and creating the HTML template:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import pyaudio
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

pya = pyaudio.PyAudio()

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        def send_async():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(audio_loop.send_text_message(text))
        
        thread = Thread(target=send_async, daemon=True)
        thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Live API - Flask UI</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .controls {
            padding: 30px;
            background: #f8f9fa;
            border-bottom: 1px solid #e0e0e0;
        }

        .control-group {
            display: flex;
            gap: 15px;
            align-items: center;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }

        .control-group label {
            font-weight: 600;
            color: #333;
        }

        .mode-selector {
            display: flex;
            gap: 10px;
        }

        .mode-btn {
            padding: 10px 20px;
            border: 2px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s;
        }

        .mode-btn:hover {
            background: #667eea;
            color: white;
        }

        .mode-btn.active {
            background: #667eea;
            color: white;
        }

        .action-btn {
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-start {
            background: #10b981;
            color: white;
        }

        .btn-start:hover {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }

        .btn-stop {
            background: #ef4444;
            color: white;
        }

        .btn-stop:hover {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }

        .btn-stop:disabled,
        .btn-start:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .content {
            padding: 30px;
        }

        .message-section {
            margin-bottom: 30px;
        }

        .message-section h2 {
            margin-bottom: 15px;
            color: #333;
        }

        .message-input-group {
            display: flex;
            gap: 10px;
        }

        .message-input {
            flex: 1;
            padding: 12px 15px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 1em;
            transition: border-color 0.3s;
        }

        .message-input:focus {
            outline: none;
            border-color: #667eea;
        }

        .btn-send {
            padding: 12px 25px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-send:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .btn-send:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .response-area {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }

        .response-text {
            color: #333;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .status {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .status.connected {
            background: #d1fae5;
            color: #065f46;
        }

        .status.disconnected {
            background: #fee2e2;
            color: #991b1b;
        }

        .status.info {
            background: #dbeafe;
            color: #1e40af;
        }

        .audio-player {
            margin-top: 20px;
            padding: 15px;
            background: #f0f0f0;
            border-radius: 8px;
            text-align: center;
        }

        audio {
            width: 100%;
            max-width: 500px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Gemini Live API</h1>
            <p>Real-time audio and video interaction with Google Gemini</p>
        </div>

        <div class="controls">
            <div class="control-group">
                <label>Video Mode:</label>
                <div class="mode-selector">
                    <button class="mode-btn active" data-mode="camera">üì∑ Camera</button>
                    <button class="mode-btn" data-mode="screen">üñ•Ô∏è Screen</button>
                    <button class="mode-btn" data-mode="none">üö´ None</button>
                </div>
            </div>
            <div class="control-group">
                <button id="startBtn" class="action-btn btn-start">‚ñ∂Ô∏è Start Session</button>
                <button id="stopBtn" class="action-btn btn-stop" disabled>‚èπÔ∏è Stop Session</button>
            </div>
        </div>

        <div class="content">
            <div id="status" class="status disconnected">Disconnected</div>

            <div class="message-section">
                <h2>üí¨ Send Message</h2>
                <div class="message-input-group">
                    <input type="text" id="messageInput" class="message-input" placeholder="Type your message here..." disabled>
                    <button id="sendBtn" class="btn-send" disabled>Send</button>
                </div>
            </div>

            <div class="message-section">
                <h2>üìù Response</h2>
                <div class="response-area">
                    <div id="responseText" class="response-text">Waiting for response...</div>
                </div>
            </div>

            <div class="audio-player" id="audioPlayer" style="display: none;">
                <h3>üîä Audio Response</h3>
                <audio id="audioElement" controls></audio>
            </div>
        </div>
    </div>

    <script>
        const socket = io();
        let currentMode = 'camera';
        let sessionActive = false;

        // Status updates
        socket.on('connect', () => {
            updateStatus('Connected to server', 'connected');
        });

        socket.on('disconnect', () => {
            updateStatus('Disconnected from server', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('connected', (data) => {
            updateStatus('Connected: ' + data.status, 'connected');
        });

        socket.on('session_started', (data) => {
            updateStatus(`Session started in ${data.mode} mode`, 'info');
            sessionActive = true;
            updateUI();
        });

        socket.on('session_stopped', (data) => {
            updateStatus('Session stopped', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('text_response', (data) => {
            const responseText = document.getElementById('responseText');
            responseText.textContent += data.text;
        });

        socket.on('audio_data', (data) => {
            // Handle audio data if needed
            // Note: Browser audio playback from PCM data requires Web Audio API
            console.log('Audio data received');
        });

        socket.on('error', (data) => {
            updateStatus('Error: ' + data.message, 'disconnected');
            alert('Error: ' + data.message);
        });

        // Mode selection
        document.querySelectorAll('.mode-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.mode-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentMode = btn.dataset.mode;
            });
        });

        // Start/Stop buttons
        document.getElementById('startBtn').addEventListener('click', () => {
            socket.emit('start_session', { mode: currentMode });
        });

        document.getElementById('stopBtn').addEventListener('click', () => {
            socket.emit('stop_session');
            document.getElementById('responseText').textContent = 'Waiting for response...';
        });

        // Send message
        document.getElementById('sendBtn').addEventListener('click', () => {
            const input = document.getElementById('messageInput');
            const text = input.value.trim();
            if (text) {
                socket.emit('send_message', { text: text });
                input.value = '';
            }
        });

        document.getElementById('messageInput').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                document.getElementById('sendBtn').click();
            }
        });

        function updateStatus(message, type) {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status ' + type;
        }

        function updateUI() {
            const startBtn = document.getElementById('startBtn');
            const stopBtn = document.getElementById('stopBtn');
            const messageInput = document.getElementById('messageInput');
            const sendBtn = document.getElementById('sendBtn');

            if (sessionActive) {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                messageInput.disabled = false;
                sendBtn.disabled = false;
            } else {
                startBtn.disabled = false;
                stopBtn.disabled = true;
                messageInput.disabled = true;
                sendBtn.disabled = true;
            }
        }
    </script>
</body>
</html>

```

Updating requirements.txt to include Flask dependencies:


```pip-requirements
google-genai 
opencv-python 
pyaudio 
pillow 
mss 
python-dotenv
flask
flask-socketio
```

Creating a README with setup and usage instructions:


```markdown
# Gemini Live API - Flask UI

A Flask web interface for Google Gemini Live API with real-time audio and video streaming capabilities.

## Features

- üéôÔ∏è Real-time audio input/output
- üì∑ Camera video streaming
- üñ•Ô∏è Screen sharing support
- üí¨ Text message interface
- üåê Modern web UI

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Ensure your `.env` file contains:
```
GOOGLE_API_KEY=your_api_key_here
```

3. Run the Flask application:
```bash
python app.py
```

4. Open your browser and navigate to:
```
http://localhost:5000
```

## Usage

1. Select your preferred video mode:
   - **Camera**: Stream from your webcam
   - **Screen**: Share your screen
   - **None**: Audio only

2. Click **Start Session** to begin

3. Type messages in the input field and click **Send** or press Enter

4. View responses in the response area

5. Click **Stop Session** when done

## Important Notes

- **Use headphones** to prevent audio feedback
- The application uses your system's default audio input/output devices
- Camera and screen sharing require appropriate permissions

## Original Script

The original command-line script (`main.py`) is still available for direct use.

```

Refining the Flask app to handle async operations more robustly:


Fixing async message handling to use the existing event loop:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import pyaudio
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

pya = pyaudio.PyAudio()

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        def send_async():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(audio_loop.send_text_message(text))
        
        thread = Thread(target=send_async, daemon=True)
        thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import pyaudio
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

pya = pyaudio.PyAudio()

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        def send_async():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(audio_loop.send_text_message(text))
        
        thread = Thread(target=send_async, daemon=True)
        thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import pyaudio
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

pya = pyaudio.PyAudio()

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

Checking for linting errors:


## Created Files:

1. **`app.py`** - Flask application with:
   - Loads `GOOGLE_API_KEY` from your `.env` file using `python-dotenv`
   - WebSocket support via Flask-SocketIO for real-time communication
   - Wraps your existing `AudioLoop` class
   - Handles async operations in separate threads
   - Supports camera, screen, or no video modes

2. **`templates/index.html`** - Web UI with:
   - Mode selection (Camera/Screen/None)
   - Start/Stop session controls
   - Text message input
   - Response display area
   - Status indicators

3. **Updated `requirements.txt`** - Added Flask and Flask-SocketIO dependencies

4. **`README.md`** - Setup and usage instructions

## To Run:

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Run the Flask app:
```bash
python app.py
```

3. Open your browser to `http://localhost:5000`

The app loads your `GOOGLE_API_KEY` from the `.env` file and provides a web interface for interacting with the Gemini Live API. The UI lets you select video modes, start/stop sessions, and send text messages while receiving audio and text responses in real time.

```shellscript
pip install -r requirements.txt
```

```shellscript
python app.py
```

---

**User**

Getting some errors

---

**Cursor**

PyAudio import error on macOS, likely due to missing PortAudio. Fixing it:


Updating the code to handle PyAudio initialization more gracefully and provide clear error messages:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

import cv2
import PIL.Image
import mss
from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

from google import genai

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

Homebrew is installed. Fixing PyAudio and checking for lint errors:


PortAudio is installed. PyAudio likely needs to be reinstalled to link against it. Creating a fix script and updating the README:


```shellscript
#!/bin/bash
# Fix PyAudio installation on macOS

echo "Reinstalling PyAudio to link with PortAudio..."
pip uninstall -y pyaudio
pip install pyaudio

echo ""
echo "PyAudio should now be fixed. Try running 'python app.py' again."

```

Updating the README with troubleshooting information:


```markdown
# Gemini Live API - Flask UI

A Flask web interface for Google Gemini Live API with real-time audio and video streaming capabilities.

## Features

- üéôÔ∏è Real-time audio input/output
- üì∑ Camera video streaming
- üñ•Ô∏è Screen sharing support
- üí¨ Text message interface
- üåê Modern web UI

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. **Fix PyAudio on macOS (if needed):**
   If you encounter PyAudio import errors, PortAudio needs to be installed:
   ```bash
   brew install portaudio
   pip uninstall pyaudio
   pip install pyaudio
   ```
   Or run the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

3. Ensure your `.env` file contains:
```
GOOGLE_API_KEY=your_api_key_here
```

4. Run the Flask application:
```bash
python app.py
```

5. Open your browser and navigate to:
```
http://localhost:5000
```

## Usage

1. Select your preferred video mode:
   - **Camera**: Stream from your webcam
   - **Screen**: Share your screen
   - **None**: Audio only

2. Click **Start Session** to begin

3. Type messages in the input field and click **Send** or press Enter

4. View responses in the response area

5. Click **Stop Session** when done

## Important Notes

- **Use headphones** to prevent audio feedback
- The application uses your system's default audio input/output devices
- Camera and screen sharing require appropriate permissions

## Original Script

The original command-line script (`main.py`) is still available for direct use.


```

```markdown
# Gemini Live API - Flask UI

A Flask web interface for Google Gemini Live API with real-time audio and video streaming capabilities.

## Features

- üéôÔ∏è Real-time audio input/output
- üì∑ Camera video streaming
- üñ•Ô∏è Screen sharing support
- üí¨ Text message interface
- üåê Modern web UI

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. **Fix PyAudio on macOS (if needed):**
   If you encounter PyAudio import errors, PortAudio needs to be installed:
   ```bash
   brew install portaudio
   pip uninstall pyaudio
   pip install pyaudio
   ```
   Or run the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

3. Ensure your `.env` file contains:
```
GOOGLE_API_KEY=your_api_key_here
```

4. Run the Flask application:
```bash
python app.py
```

5. Open your browser and navigate to:
```
http://localhost:5000
```

## Usage

1. Select your preferred video mode:
   - **Camera**: Stream from your webcam
   - **Screen**: Share your screen
   - **None**: Audio only

2. Click **Start Session** to begin

3. Type messages in the input field and click **Send** or press Enter

4. View responses in the response area

5. Click **Stop Session** when done

## Troubleshooting

### PyAudio Import Errors on macOS

If you see errors like `symbol not found in flat namespace '_PaMacCore_SetupChannelMap'`:

1. Install PortAudio via Homebrew:
   ```bash
   brew install portaudio
   ```

2. Reinstall PyAudio:
   ```bash
   pip uninstall pyaudio
   pip install pyaudio
   ```

3. Or use the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

The app will still run without PyAudio, but audio features will be disabled.

## Important Notes

- **Use headphones** to prevent audio feedback
- The application uses your system's default audio input/output devices
- Camera and screen sharing require appropriate permissions
- If PyAudio is not available, the app will run but audio features will be disabled

## Original Script

The original command-line script (`main.py`) is still available for direct use.


```

## Changes Made:

1. **Graceful error handling** ‚Äî The app handles PyAudio import errors and continues running (audio features disabled if PyAudio isn't available).

2. **Fix script** ‚Äî Created `fix_pyaudio.sh` to reinstall PyAudio.

3. **Updated README** ‚Äî Added troubleshooting steps for PyAudio issues.

## To Fix PyAudio:

Since PortAudio is already installed, reinstall PyAudio:

```bash
pip uninstall pyaudio
pip install pyaudio
```

Or run the fix script:
```bash
./fix_pyaudio.sh
```

The app should start even if PyAudio has issues; it will show warnings and disable audio features. After fixing PyAudio, restart the app to enable audio.

Try running `python app.py` again. It should start, and you'll see warnings if PyAudio isn't working. After fixing PyAudio, restart the app for full functionality.

```shellscript
pip uninstall pyaudio
pip install pyaudio
```

```shellscript
./fix_pyaudio.sh
```

---

**User**

getting error 

---

**Cursor**

Checking dependencies and fixing the PIL import issue:


Pillow is installed, but PIL isn't being found. Making the import more robust and checking the virtual environment:


PIL works, but the venv may be missing dependencies. Making imports more robust and ensuring dependencies are installed:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PIL.Image.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PIL.Image.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)


```

Pillow is installed in the base environment, but the venv doesn't have it. Installing dependencies in the venv:


---

**User**

I installed pillow, got new error

---

**Cursor**

Port 5000 is in use (often by macOS AirPlay Receiver). Updating the app to use a different port:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            await self.session.send(input=msg)

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

Updating the README to reflect the port change:


```markdown
# Gemini Live API - Flask UI

A Flask web interface for Google Gemini Live API with real-time audio and video streaming capabilities.

## Features

- üéôÔ∏è Real-time audio input/output
- üì∑ Camera video streaming
- üñ•Ô∏è Screen sharing support
- üí¨ Text message interface
- üåê Modern web UI

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. **Fix PyAudio on macOS (if needed):**
   If you encounter PyAudio import errors, PortAudio needs to be installed:
   ```bash
   brew install portaudio
   pip uninstall pyaudio
   pip install pyaudio
   ```
   Or run the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

3. Ensure your `.env` file contains:
```
GOOGLE_API_KEY=your_api_key_here
```

4. Run the Flask application:
```bash
python app.py
```

5. Open your browser and navigate to:
```
http://localhost:5001
```

**Note:** The app uses port 5001 by default to avoid conflicts with macOS AirPlay Receiver (which uses port 5000). You can change the port by setting the `FLASK_PORT` environment variable:
```bash
FLASK_PORT=8080 python app.py
```

## Usage

1. Select your preferred video mode:
   - **Camera**: Stream from your webcam
   - **Screen**: Share your screen
   - **None**: Audio only

2. Click **Start Session** to begin

3. Type messages in the input field and click **Send** or press Enter

4. View responses in the response area

5. Click **Stop Session** when done

## Troubleshooting

### PyAudio Import Errors on macOS

If you see errors like `symbol not found in flat namespace '_PaMacCore_SetupChannelMap'`:

1. Install PortAudio via Homebrew:
   ```bash
   brew install portaudio
   ```

2. Reinstall PyAudio:
   ```bash
   pip uninstall pyaudio
   pip install pyaudio
   ```

3. Or use the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

The app will still run without PyAudio, but audio features will be disabled.

## Important Notes

- **Use headphones** to prevent audio feedback
- The application uses your system's default audio input/output devices
- Camera and screen sharing require appropriate permissions
- If PyAudio is not available, the app will run but audio features will be disabled

## Original Script

The original command-line script (`main.py`) is still available for direct use.


```

```markdown
# Gemini Live API - Flask UI

A Flask web interface for Google Gemini Live API with real-time audio and video streaming capabilities.

## Features

- üéôÔ∏è Real-time audio input/output
- üì∑ Camera video streaming
- üñ•Ô∏è Screen sharing support
- üí¨ Text message interface
- üåê Modern web UI

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. **Fix PyAudio on macOS (if needed):**
   If you encounter PyAudio import errors, PortAudio needs to be installed:
   ```bash
   brew install portaudio
   pip uninstall pyaudio
   pip install pyaudio
   ```
   Or run the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

3. Ensure your `.env` file contains:
```
GOOGLE_API_KEY=your_api_key_here
```

4. Run the Flask application:
```bash
python app.py
```

5. Open your browser and navigate to:
```
http://localhost:5001
```

**Note:** The app uses port 5001 by default to avoid conflicts with macOS AirPlay Receiver (which uses port 5000). You can change the port by setting the `FLASK_PORT` environment variable:
```bash
FLASK_PORT=8080 python app.py
```

## Usage

1. Select your preferred video mode:
   - **Camera**: Stream from your webcam
   - **Screen**: Share your screen
   - **None**: Audio only

2. Click **Start Session** to begin

3. Type messages in the input field and click **Send** or press Enter

4. View responses in the response area

5. Click **Stop Session** when done

## Troubleshooting

### PyAudio Import Errors on macOS

If you see errors like `symbol not found in flat namespace '_PaMacCore_SetupChannelMap'`:

1. Install PortAudio via Homebrew:
   ```bash
   brew install portaudio
   ```

2. Reinstall PyAudio:
   ```bash
   pip uninstall pyaudio
   pip install pyaudio
   ```

3. Or use the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

The app will still run without PyAudio, but audio features will be disabled.

### Port Already in Use

If you see "Address already in use" or "Port 5000 is in use":
- The app now defaults to port 5001 to avoid macOS AirPlay Receiver conflicts
- To use a different port, set `FLASK_PORT` environment variable:
  ```bash
  FLASK_PORT=8080 python app.py
  ```
- Or disable AirPlay Receiver: System Preferences ‚Üí General ‚Üí AirDrop & Handoff ‚Üí AirPlay Receiver

## Important Notes

- **Use headphones** to prevent audio feedback
- The application uses your system's default audio input/output devices
- Camera and screen sharing require appropriate permissions
- If PyAudio is not available, the app will run but audio features will be disabled

## Original Script

The original command-line script (`main.py`) is still available for direct use.


```

Fixed the port conflict. The app now defaults to port 5001 instead of 5000 to avoid macOS AirPlay Receiver conflicts.

## Changes Made:

1. Changed default port from 5000 to 5001
2. Added startup messages showing the correct URL
3. Made port configurable via `FLASK_PORT` environment variable
4. Updated README with port information

## To Run:

```bash
python app.py
```

The app will start on port 5001 and display:
```
üöÄ Starting Flask server on http://localhost:5001
üìù Open your browser and navigate to: http://localhost:5001
```

Open `http://localhost:5001` in your browser.

**Note:** The linter warnings are about imports the IDE can't resolve; they won't affect runtime if the packages are installed in your virtual environment. The app should run now.

If you still see PyAudio warnings, that's expected‚Äîaudio features will be disabled, but the web UI will still work for text messaging.

```shellscript
python app.py
```

```plaintext
üöÄ Starting Flask server on http://localhost:5001
üìù Open your browser and navigate to: http://localhost:5001
```

---

**User**

Got the following errors. I think we need to ask for permissions

---

**Cursor**

Fixing the deprecation warning and improving permission handling. Updating the code:


Fixing the deprecation warnings and improving permission handling:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            await self.session.send(input=text or ".", end_of_turn=True)

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        cap = await asyncio.to_thread(cv2.VideoCapture, 0)
        while self.running:
            frame = await asyncio.to_thread(self._get_frame, cap)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)
        cap.release()

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('error', {
                    'message': 'Camera access denied or camera not available. Please grant camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('error', {
                'message': f'Camera error: {str(e)}. Please check camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        while self.running:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('error', {
                    'message': 'Camera access denied or camera not available. Please grant camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('error', {
                'message': f'Camera error: {str(e)}. Please check camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio input disabled.'}, room=self.session_id)
            return
        
        try:
            mic_info = pya.get_default_input_device_info()
            self.audio_stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=SEND_SAMPLE_RATE,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=CHUNK_SIZE,
            )
            socketio.emit('info', {'message': 'Microphone access granted. Starting audio input...'}, room=self.session_id)
            kwargs = {"exception_on_overflow": False} if __debug__ else {}
            while self.running:
                data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
                await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})
        except Exception as e:
            socketio.emit('error', {
                'message': f'Microphone access denied or error: {str(e)}. Please grant microphone permissions in System Settings ‚Üí Privacy & Security ‚Üí Microphone.'
            }, room=self.session_id)

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

Adding handling for info messages in the HTML template:


```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Live API - Flask UI</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .controls {
            padding: 30px;
            background: #f8f9fa;
            border-bottom: 1px solid #e0e0e0;
        }

        .control-group {
            display: flex;
            gap: 15px;
            align-items: center;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }

        .control-group label {
            font-weight: 600;
            color: #333;
        }

        .mode-selector {
            display: flex;
            gap: 10px;
        }

        .mode-btn {
            padding: 10px 20px;
            border: 2px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s;
        }

        .mode-btn:hover {
            background: #667eea;
            color: white;
        }

        .mode-btn.active {
            background: #667eea;
            color: white;
        }

        .action-btn {
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-start {
            background: #10b981;
            color: white;
        }

        .btn-start:hover {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }

        .btn-stop {
            background: #ef4444;
            color: white;
        }

        .btn-stop:hover {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }

        .btn-stop:disabled,
        .btn-start:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .content {
            padding: 30px;
        }

        .message-section {
            margin-bottom: 30px;
        }

        .message-section h2 {
            margin-bottom: 15px;
            color: #333;
        }

        .message-input-group {
            display: flex;
            gap: 10px;
        }

        .message-input {
            flex: 1;
            padding: 12px 15px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 1em;
            transition: border-color 0.3s;
        }

        .message-input:focus {
            outline: none;
            border-color: #667eea;
        }

        .btn-send {
            padding: 12px 25px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-send:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .btn-send:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .response-area {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }

        .response-text {
            color: #333;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .status {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .status.connected {
            background: #d1fae5;
            color: #065f46;
        }

        .status.disconnected {
            background: #fee2e2;
            color: #991b1b;
        }

        .status.info {
            background: #dbeafe;
            color: #1e40af;
        }

        .audio-player {
            margin-top: 20px;
            padding: 15px;
            background: #f0f0f0;
            border-radius: 8px;
            text-align: center;
        }

        audio {
            width: 100%;
            max-width: 500px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Gemini Live API</h1>
            <p>Real-time audio and video interaction with Google Gemini</p>
        </div>

        <div class="controls">
            <div class="control-group">
                <label>Video Mode:</label>
                <div class="mode-selector">
                    <button class="mode-btn active" data-mode="camera">üì∑ Camera</button>
                    <button class="mode-btn" data-mode="screen">üñ•Ô∏è Screen</button>
                    <button class="mode-btn" data-mode="none">üö´ None</button>
                </div>
            </div>
            <div class="control-group">
                <button id="startBtn" class="action-btn btn-start">‚ñ∂Ô∏è Start Session</button>
                <button id="stopBtn" class="action-btn btn-stop" disabled>‚èπÔ∏è Stop Session</button>
            </div>
        </div>

        <div class="content">
            <div id="status" class="status disconnected">Disconnected</div>

            <div class="message-section">
                <h2>üí¨ Send Message</h2>
                <div class="message-input-group">
                    <input type="text" id="messageInput" class="message-input" placeholder="Type your message here..." disabled>
                    <button id="sendBtn" class="btn-send" disabled>Send</button>
                </div>
            </div>

            <div class="message-section">
                <h2>üìù Response</h2>
                <div class="response-area">
                    <div id="responseText" class="response-text">Waiting for response...</div>
                </div>
            </div>

            <div class="audio-player" id="audioPlayer" style="display: none;">
                <h3>üîä Audio Response</h3>
                <audio id="audioElement" controls></audio>
            </div>
        </div>
    </div>

    <script>
        const socket = io();
        let currentMode = 'camera';
        let sessionActive = false;

        // Status updates
        socket.on('connect', () => {
            updateStatus('Connected to server', 'connected');
        });

        socket.on('disconnect', () => {
            updateStatus('Disconnected from server', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('connected', (data) => {
            updateStatus('Connected: ' + data.status, 'connected');
        });

        socket.on('session_started', (data) => {
            updateStatus(`Session started in ${data.mode} mode`, 'info');
            sessionActive = true;
            updateUI();
        });

        socket.on('session_stopped', (data) => {
            updateStatus('Session stopped', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('text_response', (data) => {
            const responseText = document.getElementById('responseText');
            responseText.textContent += data.text;
        });

        socket.on('audio_data', (data) => {
            // Handle audio data if needed
            // Note: Browser audio playback from PCM data requires Web Audio API
            console.log('Audio data received');
        });

        socket.on('error', (data) => {
            updateStatus('Error: ' + data.message, 'disconnected');
            alert('Error: ' + data.message);
        });

        socket.on('info', (data) => {
            updateStatus('Info: ' + data.message, 'info');
        });

        // Mode selection
        document.querySelectorAll('.mode-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.mode-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentMode = btn.dataset.mode;
            });
        });

        // Start/Stop buttons
        document.getElementById('startBtn').addEventListener('click', () => {
            socket.emit('start_session', { mode: currentMode });
        });

        document.getElementById('stopBtn').addEventListener('click', () => {
            socket.emit('stop_session');
            document.getElementById('responseText').textContent = 'Waiting for response...';
        });

        // Send message
        document.getElementById('sendBtn').addEventListener('click', () => {
            const input = document.getElementById('messageInput');
            const text = input.value.trim();
            if (text) {
                socket.emit('send_message', { text: text });
                input.value = '';
            }
        });

        document.getElementById('messageInput').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                document.getElementById('sendBtn').click();
            }
        });

        function updateStatus(message, type) {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status ' + type;
        }

        function updateUI() {
            const startBtn = document.getElementById('startBtn');
            const stopBtn = document.getElementById('stopBtn');
            const messageInput = document.getElementById('messageInput');
            const sendBtn = document.getElementById('sendBtn');

            if (sessionActive) {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                messageInput.disabled = false;
                sendBtn.disabled = false;
            } else {
                startBtn.disabled = false;
                stopBtn.disabled = true;
                messageInput.disabled = true;
                sendBtn.disabled = true;
            }
        }
    </script>
</body>
</html>


```

## Changes Made:

1. Fixed deprecation warnings:
   - Replaced deprecated `session.send()` with `send_realtime_input()` for audio/video
   - Used `send_client_content()` for text messages

2. Improved permission handling:
   - Added try/except around camera access with clear error messages
   - Added try/except around microphone access with clear error messages
   - Added info messages when permissions are granted
   - Provided instructions on where to grant permissions (System Settings)

3. Updated UI:
   - Added handling for 'info' events to display permission status messages

## What This Fixes:

- Deprecation warnings: The app now uses the current API methods
- Permission errors: Clear messages when camera/microphone access is denied
- User guidance: Instructions on where to grant permissions in macOS System Settings

The app will now:
- Show info messages when permissions are granted
- Show clear error messages with instructions if permissions are denied
- Use the current API methods (no deprecation warnings)

When you run the app and start a session, it will:
1. Request camera/microphone permissions (macOS will prompt you)
2. Show status messages about permission grants/denials
3. Provide clear instructions if permissions need to be granted manually

The deprecation warnings should be gone, and permission issues will be clearer.

---

**User**

I am getting errors. Error: PyAudio not available. Audio output disabled. same for video

---

**Cursor**

Checking the code to diagnose the audio and video errors:


Updating the code to allow sessions to run without audio/video and to handle missing features gracefully:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('error', {
                    'message': 'Camera access denied or camera not available. Please grant camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('error', {
                'message': f'Camera error: {str(e)}. Please check camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio input disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            mic_info = pya.get_default_input_device_info()
            self.audio_stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=SEND_SAMPLE_RATE,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=CHUNK_SIZE,
            )
            socketio.emit('info', {'message': 'Microphone access granted. Starting audio input...'}, room=self.session_id)
            kwargs = {"exception_on_overflow": False} if __debug__ else {}
            while self.running:
                data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
                await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})
        except Exception as e:
            socketio.emit('info', {
                'message': f'Microphone not available: {str(e)}. Text-only mode available. To enable audio, grant microphone permissions in System Settings ‚Üí Privacy & Security ‚Üí Microphone.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('error', {'message': 'PyAudio not available. Audio output disabled.'}, room=self.session_id)
            return
        
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        while self.running:
            bytestream = await self.audio_in_queue.get()
            await asyncio.to_thread(stream.write, bytestream)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('error', {'message': 'OpenCV not available. Camera features disabled.'}, room=self.session_id)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('error', {
                    'message': 'Camera access denied or camera not available. Please grant camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('error', {
                'message': f'Camera error: {str(e)}. Please check camera permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio input disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            mic_info = pya.get_default_input_device_info()
            self.audio_stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=SEND_SAMPLE_RATE,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=CHUNK_SIZE,
            )
            socketio.emit('info', {'message': 'Microphone access granted. Starting audio input...'}, room=self.session_id)
            kwargs = {"exception_on_overflow": False} if __debug__ else {}
            while self.running:
                data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
                await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})
        except Exception as e:
            socketio.emit('info', {
                'message': f'Microphone not available: {str(e)}. Text-only mode available. To enable audio, grant microphone permissions in System Settings ‚Üí Privacy & Security ‚Üí Microphone.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio output disabled. Text responses will still work.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=RECEIVE_SAMPLE_RATE,
                output=True,
            )
            while self.running:
                bytestream = await self.audio_in_queue.get()
                await asyncio.to_thread(stream.write, bytestream)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Audio output not available: {str(e)}. Text responses will still work.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('info', {'message': 'OpenCV not available. Camera features disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('info', {
                    'message': 'Camera not available. Text-only mode available. To enable camera, grant permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                # Keep the task running but don't do anything
                while self.running:
                    await asyncio.sleep(1.0)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('info', {
                'message': f'Camera not available: {str(e)}. Text-only mode available. To enable camera, check permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('error', {'message': 'mss not available. Screen capture features disabled.'}, room=self.session_id)
            return
        while self.running:
            frame = await asyncio.to_thread(self._get_screen)
            if frame is None:
                break
            await asyncio.sleep(1.0)
            await self.out_queue.put(frame)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio input disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            mic_info = pya.get_default_input_device_info()
            self.audio_stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=SEND_SAMPLE_RATE,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=CHUNK_SIZE,
            )
            socketio.emit('info', {'message': 'Microphone access granted. Starting audio input...'}, room=self.session_id)
            kwargs = {"exception_on_overflow": False} if __debug__ else {}
            while self.running:
                data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
                await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})
        except Exception as e:
            socketio.emit('info', {
                'message': f'Microphone not available: {str(e)}. Text-only mode available. To enable audio, grant microphone permissions in System Settings ‚Üí Privacy & Security ‚Üí Microphone.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio output disabled. Text responses will still work.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=RECEIVE_SAMPLE_RATE,
                output=True,
            )
            while self.running:
                bytestream = await self.audio_in_queue.get()
                await asyncio.to_thread(stream.write, bytestream)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Audio output not available: {str(e)}. Text responses will still work.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
from threading import Thread

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('info', {'message': 'OpenCV not available. Camera features disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('info', {
                    'message': 'Camera not available. Text-only mode available. To enable camera, grant permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                # Keep the task running but don't do anything
                while self.running:
                    await asyncio.sleep(1.0)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('info', {
                'message': f'Camera not available: {str(e)}. Text-only mode available. To enable camera, check permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('info', {'message': 'mss not available. Screen capture features disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            while self.running:
                frame = await asyncio.to_thread(self._get_screen)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Screen capture not available: {str(e)}. Text-only mode available.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio input disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            mic_info = pya.get_default_input_device_info()
            self.audio_stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=SEND_SAMPLE_RATE,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=CHUNK_SIZE,
            )
            socketio.emit('info', {'message': 'Microphone access granted. Starting audio input...'}, room=self.session_id)
            kwargs = {"exception_on_overflow": False} if __debug__ else {}
            while self.running:
                data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
                await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})
        except Exception as e:
            socketio.emit('info', {
                'message': f'Microphone not available: {str(e)}. Text-only mode available. To enable audio, grant microphone permissions in System Settings ‚Üí Privacy & Security ‚Üí Microphone.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio output disabled. Text responses will still work.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=RECEIVE_SAMPLE_RATE,
                output=True,
            )
            while self.running:
                bytestream = await self.audio_in_queue.get()
                await asyncio.to_thread(stream.write, bytestream)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Audio output not available: {str(e)}. Text responses will still work.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Live API - Flask UI</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .controls {
            padding: 30px;
            background: #f8f9fa;
            border-bottom: 1px solid #e0e0e0;
        }

        .control-group {
            display: flex;
            gap: 15px;
            align-items: center;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }

        .control-group label {
            font-weight: 600;
            color: #333;
        }

        .mode-selector {
            display: flex;
            gap: 10px;
        }

        .mode-btn {
            padding: 10px 20px;
            border: 2px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s;
        }

        .mode-btn:hover {
            background: #667eea;
            color: white;
        }

        .mode-btn.active {
            background: #667eea;
            color: white;
        }

        .action-btn {
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-start {
            background: #10b981;
            color: white;
        }

        .btn-start:hover {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }

        .btn-stop {
            background: #ef4444;
            color: white;
        }

        .btn-stop:hover {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }

        .btn-stop:disabled,
        .btn-start:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .content {
            padding: 30px;
        }

        .message-section {
            margin-bottom: 30px;
        }

        .message-section h2 {
            margin-bottom: 15px;
            color: #333;
        }

        .message-input-group {
            display: flex;
            gap: 10px;
        }

        .message-input {
            flex: 1;
            padding: 12px 15px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 1em;
            transition: border-color 0.3s;
        }

        .message-input:focus {
            outline: none;
            border-color: #667eea;
        }

        .btn-send {
            padding: 12px 25px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-send:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .btn-send:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .response-area {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }

        .response-text {
            color: #333;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .status {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .status.connected {
            background: #d1fae5;
            color: #065f46;
        }

        .status.disconnected {
            background: #fee2e2;
            color: #991b1b;
        }

        .status.info {
            background: #dbeafe;
            color: #1e40af;
        }

        .audio-player {
            margin-top: 20px;
            padding: 15px;
            background: #f0f0f0;
            border-radius: 8px;
            text-align: center;
        }

        audio {
            width: 100%;
            max-width: 500px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Gemini Live API</h1>
            <p>Real-time audio and video interaction with Google Gemini</p>
        </div>

        <div class="controls">
            <div class="control-group">
                <label>Video Mode:</label>
                <div class="mode-selector">
                    <button class="mode-btn active" data-mode="camera">üì∑ Camera</button>
                    <button class="mode-btn" data-mode="screen">üñ•Ô∏è Screen</button>
                    <button class="mode-btn" data-mode="none">üö´ None</button>
                </div>
            </div>
            <div class="control-group">
                <button id="startBtn" class="action-btn btn-start">‚ñ∂Ô∏è Start Session</button>
                <button id="stopBtn" class="action-btn btn-stop" disabled>‚èπÔ∏è Stop Session</button>
            </div>
        </div>

        <div class="content">
            <div id="status" class="status disconnected">Disconnected</div>

            <div class="message-section">
                <h2>üí¨ Send Message</h2>
                <div class="message-input-group">
                    <input type="text" id="messageInput" class="message-input" placeholder="Type your message here..." disabled>
                    <button id="sendBtn" class="btn-send" disabled>Send</button>
                </div>
            </div>

            <div class="message-section">
                <h2>üìù Response</h2>
                <div class="response-area">
                    <div id="responseText" class="response-text">Waiting for response...</div>
                </div>
            </div>

            <div class="audio-player" id="audioPlayer" style="display: none;">
                <h3>üîä Audio Response</h3>
                <audio id="audioElement" controls></audio>
            </div>
        </div>
    </div>

    <script>
        const socket = io();
        let currentMode = 'camera';
        let sessionActive = false;

        // Status updates
        socket.on('connect', () => {
            updateStatus('Connected to server', 'connected');
        });

        socket.on('disconnect', () => {
            updateStatus('Disconnected from server', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('connected', (data) => {
            updateStatus('Connected: ' + data.status, 'connected');
        });

        socket.on('session_started', (data) => {
            updateStatus(`Session started in ${data.mode} mode`, 'info');
            sessionActive = true;
            updateUI();
        });

        socket.on('session_stopped', (data) => {
            updateStatus('Session stopped', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('text_response', (data) => {
            const responseText = document.getElementById('responseText');
            responseText.textContent += data.text;
        });

        socket.on('audio_data', (data) => {
            // Handle audio data if needed
            // Note: Browser audio playback from PCM data requires Web Audio API
            console.log('Audio data received');
        });

        socket.on('error', (data) => {
            // Only show alerts for critical errors, not for disabled features
            if (data.message.includes('not available') || data.message.includes('disabled')) {
                updateStatus('Info: ' + data.message, 'info');
            } else {
                updateStatus('Error: ' + data.message, 'disconnected');
                alert('Error: ' + data.message);
            }
        });

        socket.on('info', (data) => {
            updateStatus('Info: ' + data.message, 'info');
        });

        // Mode selection
        document.querySelectorAll('.mode-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.mode-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentMode = btn.dataset.mode;
            });
        });

        // Start/Stop buttons
        document.getElementById('startBtn').addEventListener('click', () => {
            socket.emit('start_session', { mode: currentMode });
        });

        document.getElementById('stopBtn').addEventListener('click', () => {
            socket.emit('stop_session');
            document.getElementById('responseText').textContent = 'Waiting for response...';
        });

        // Send message
        document.getElementById('sendBtn').addEventListener('click', () => {
            const input = document.getElementById('messageInput');
            const text = input.value.trim();
            if (text) {
                socket.emit('send_message', { text: text });
                input.value = '';
            }
        });

        document.getElementById('messageInput').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                document.getElementById('sendBtn').click();
            }
        });

        function updateStatus(message, type) {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status ' + type;
        }

        function updateUI() {
            const startBtn = document.getElementById('startBtn');
            const stopBtn = document.getElementById('stopBtn');
            const messageInput = document.getElementById('messageInput');
            const sendBtn = document.getElementById('sendBtn');

            if (sessionActive) {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                messageInput.disabled = false;
                sendBtn.disabled = false;
            } else {
                startBtn.disabled = false;
                stopBtn.disabled = true;
                messageInput.disabled = true;
                sendBtn.disabled = true;
            }
        }
    </script>
</body>
</html>


```

Updated the app to handle missing audio/video gracefully. Changes:

## Changes Made:

1. **Changed error messages to info messages** ‚Äî When PyAudio or camera aren't available, it shows info messages instead of error alerts, so the session can still run.

2. **Text-only mode** ‚Äî The app works in text-only mode even without audio/video. You can still send text messages and get text responses.

3. **Tasks keep running** ‚Äî When features are disabled, the tasks stay alive (sleeping) so the session doesn't crash.

4. **Better UI handling** ‚Äî The frontend no longer shows alert popups for expected issues like "PyAudio not available" ‚Äî these are shown as info messages instead.

5. **Clear messaging** ‚Äî All messages now indicate that "Text-only mode available" so you know the app still works.

## What This Means:

- The app will start and run even without PyAudio or camera access
- You'll see info messages (not error alerts) about disabled features
- Text messaging will work ‚Äî you can send messages and get text responses
- The session won't crash when features are unavailable

When you start a session, you'll see messages like:
- "PyAudio not available. Audio input disabled. Text-only mode available."
- "Camera not available. Text-only mode available."

These are informational, not errors. You can still use the app for text conversations with Gemini.

To enable audio/video later, fix PyAudio and grant camera permissions, then restart the session.

---

**User**

I need to add something to the Info.plist it says. I am stil lgetting errors:

Error: PyAudio not available. Audio output disabled.

---

**Cursor**

Checking for remaining error emissions and addressing the Info.plist warning:


Checking for remaining error emissions and addressing both issues:


Suppressing the macOS camera deprecation warning and ensuring no error messages are emitted. The error may be from a cached browser version. Adding warning suppression and creating a note about Info.plist:


```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
import warnings
from threading import Thread

# Suppress macOS camera deprecation warnings
os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'
warnings.filterwarnings('ignore', category=DeprecationWarning)

# Try to import optional dependencies with graceful error handling
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('info', {'message': 'OpenCV not available. Camera features disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('info', {
                    'message': 'Camera not available. Text-only mode available. To enable camera, grant permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                # Keep the task running but don't do anything
                while self.running:
                    await asyncio.sleep(1.0)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('info', {
                'message': f'Camera not available: {str(e)}. Text-only mode available. To enable camera, check permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('info', {'message': 'mss not available. Screen capture features disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            while self.running:
                frame = await asyncio.to_thread(self._get_screen)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Screen capture not available: {str(e)}. Text-only mode available.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio input disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            mic_info = pya.get_default_input_device_info()
            self.audio_stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=SEND_SAMPLE_RATE,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=CHUNK_SIZE,
            )
            socketio.emit('info', {'message': 'Microphone access granted. Starting audio input...'}, room=self.session_id)
            kwargs = {"exception_on_overflow": False} if __debug__ else {}
            while self.running:
                data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
                await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})
        except Exception as e:
            socketio.emit('info', {
                'message': f'Microphone not available: {str(e)}. Text-only mode available. To enable audio, grant microphone permissions in System Settings ‚Üí Privacy & Security ‚Üí Microphone.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio output disabled. Text responses will still work.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=RECEIVE_SAMPLE_RATE,
                output=True,
            )
            while self.running:
                bytestream = await self.audio_in_queue.get()
                await asyncio.to_thread(stream.write, bytestream)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Audio output not available: {str(e)}. Text responses will still work.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```python
# -*- coding: utf-8 -*-
import asyncio
import base64
import io
import os
import sys
import traceback
import warnings
from threading import Thread

# Suppress macOS camera deprecation warnings
os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'
warnings.filterwarnings('ignore', category=DeprecationWarning)

# Try to import optional dependencies with graceful error handling
try:
    # Suppress OpenCV macOS warnings
    import warnings
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=DeprecationWarning)
        import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV (cv2) not available. Camera features will be disabled.")

try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) not available. Image processing features will be disabled.")

try:
    import mss
    MSS_AVAILABLE = True
except ImportError:
    MSS_AVAILABLE = False
    print("Warning: mss not available. Screen capture features will be disabled.")

from dotenv import load_dotenv
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("Error: google-genai not available. Please install: pip install google-genai")

# Load environment variables
load_dotenv()

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup
    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup

# Try to import pyaudio, handle errors gracefully
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    print(f"Warning: PyAudio not available: {e}")
    print("\nTo fix PyAudio on macOS, run:")
    print("  brew install portaudio")
    print("  pip uninstall pyaudio")
    print("  pip install pyaudio")

FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 1024

MODEL = "models/gemini-2.5-flash-native-audio-preview-09-2025"
DEFAULT_MODE = "camera"

# Initialize Google AI client with API key from .env
if not GENAI_AVAILABLE:
    raise ImportError("google-genai is required. Install with: pip install google-genai")

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in .env file")

client = genai.Client(api_key=api_key, http_options={"api_version": "v1beta"})
CONFIG = {"response_modalities": ["AUDIO"]}

# Initialize PyAudio only if available
pya = None
if PYAUDIO_AVAILABLE:
    try:
        pya = pyaudio.PyAudio()
    except Exception as e:
        print(f"Warning: Failed to initialize PyAudio: {e}")
        print("\nTo fix PyAudio on macOS, run:")
        print("  brew install portaudio")
        print("  pip uninstall pyaudio")
        print("  pip install pyaudio")
        PYAUDIO_AVAILABLE = False

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global session management
active_sessions = {}


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE, session_id=None):
        self.video_mode = video_mode
        self.session_id = session_id
        self.audio_in_queue = None
        self.out_queue = None
        self.session = None
        self.audio_stream = None
        self.running = False
        self.event_loop = None

    def _get_frame(self, cap):
        if not CV2_AVAILABLE or not PIL_AVAILABLE:
            return None
        ret, frame = cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img = PILImage.fromarray(frame_rgb)
        img.thumbnail([1024, 1024])

        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)

        mime_type = "image/jpeg"
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_frames(self):
        if not CV2_AVAILABLE:
            socketio.emit('info', {'message': 'OpenCV not available. Camera features disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            cap = await asyncio.to_thread(cv2.VideoCapture, 0)
            if not cap.isOpened():
                socketio.emit('info', {
                    'message': 'Camera not available. Text-only mode available. To enable camera, grant permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
                }, room=self.session_id)
                # Keep the task running but don't do anything
                while self.running:
                    await asyncio.sleep(1.0)
                return
            
            socketio.emit('info', {'message': 'Camera access granted. Starting video stream...'}, room=self.session_id)
            
            while self.running:
                frame = await asyncio.to_thread(self._get_frame, cap)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
            cap.release()
        except Exception as e:
            socketio.emit('info', {
                'message': f'Camera not available: {str(e)}. Text-only mode available. To enable camera, check permissions in System Settings ‚Üí Privacy & Security ‚Üí Camera.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    def _get_screen(self):
        if not MSS_AVAILABLE or not PIL_AVAILABLE:
            return None
        sct = mss.mss()
        monitor = sct.monitors[0]
        i = sct.grab(monitor)
        mime_type = "image/jpeg"
        image_bytes = mss.tools.to_png(i.rgb, i.size)
        img = PILImage.open(io.BytesIO(image_bytes))
        image_io = io.BytesIO()
        img.save(image_io, format="jpeg")
        image_io.seek(0)
        image_bytes = image_io.read()
        return {"mime_type": mime_type, "data": base64.b64encode(image_bytes).decode()}

    async def get_screen(self):
        if not MSS_AVAILABLE:
            socketio.emit('info', {'message': 'mss not available. Screen capture features disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            while self.running:
                frame = await asyncio.to_thread(self._get_screen)
                if frame is None:
                    break
                await asyncio.sleep(1.0)
                await self.out_queue.put(frame)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Screen capture not available: {str(e)}. Text-only mode available.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_realtime(self):
        while self.running:
            msg = await self.out_queue.get()
            # Use the new API method instead of deprecated send()
            if "mime_type" in msg:
                if msg["mime_type"].startswith("image/"):
                    # Send as media (image/video)
                    from google.genai import types
                    blob = types.Blob(
                        data=base64.b64decode(msg["data"]),
                        mime_type=msg["mime_type"]
                    )
                    await self.session.send_realtime_input(media=blob)
                elif msg["mime_type"] == "audio/pcm":
                    # Send as audio
                    from google.genai import types
                    blob = types.Blob(
                        data=msg["data"],
                        mime_type="audio/pcm;rate=16000"
                    )
                    await self.session.send_realtime_input(audio=blob)
            else:
                # Fallback for other message types
                await self.session.send_realtime_input(text=str(msg))

    async def listen_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio input disabled. Text-only mode available.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            mic_info = pya.get_default_input_device_info()
            self.audio_stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=SEND_SAMPLE_RATE,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=CHUNK_SIZE,
            )
            socketio.emit('info', {'message': 'Microphone access granted. Starting audio input...'}, room=self.session_id)
            kwargs = {"exception_on_overflow": False} if __debug__ else {}
            while self.running:
                data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
                await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})
        except Exception as e:
            socketio.emit('info', {
                'message': f'Microphone not available: {str(e)}. Text-only mode available. To enable audio, grant microphone permissions in System Settings ‚Üí Privacy & Security ‚Üí Microphone.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def receive_audio(self):
        while self.running:
            turn = self.session.receive()
            async for response in turn:
                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    # Emit audio data to client
                    socketio.emit('audio_data', {'data': base64.b64encode(data).decode()}, room=self.session_id)
                    continue
                if text := response.text:
                    socketio.emit('text_response', {'text': text}, room=self.session_id)

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        if not PYAUDIO_AVAILABLE or pya is None:
            socketio.emit('info', {'message': 'PyAudio not available. Audio output disabled. Text responses will still work.'}, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)
            return
        
        try:
            stream = await asyncio.to_thread(
                pya.open,
                format=FORMAT,
                channels=CHANNELS,
                rate=RECEIVE_SAMPLE_RATE,
                output=True,
            )
            while self.running:
                bytestream = await self.audio_in_queue.get()
                await asyncio.to_thread(stream.write, bytestream)
        except Exception as e:
            socketio.emit('info', {
                'message': f'Audio output not available: {str(e)}. Text responses will still work.'
            }, room=self.session_id)
            # Keep the task running but don't do anything
            while self.running:
                await asyncio.sleep(1.0)

    async def send_text_message(self, text):
        if self.session:
            # Use send_client_content for turn-based text messages
            from google.genai import types
            await self.session.send_client_content(
                turns=types.Content(
                    role='user',
                    parts=[types.Part(text=text or ".")]
                ),
                turn_complete=True
            )

    async def run(self):
        try:
            self.event_loop = asyncio.get_event_loop()
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session
                self.running = True

                self.audio_in_queue = asyncio.Queue()
                self.out_queue = asyncio.Queue(maxsize=5)

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())
                
                if self.video_mode == "camera":
                    tg.create_task(self.get_frames())
                elif self.video_mode == "screen":
                    tg.create_task(self.get_screen())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                # Keep running until stopped
                while self.running:
                    await asyncio.sleep(0.1)

        except asyncio.CancelledError:
            pass
        except Exception as e:
            if self.audio_stream:
                self.audio_stream.close()
            socketio.emit('error', {'message': str(e)}, room=self.session_id)
            traceback.print_exception(type(e), e, e.__traceback__)

    def stop(self):
        self.running = False


@app.route('/')
def index():
    return render_template('index.html')


@socketio.on('connect')
def handle_connect():
    emit('connected', {'status': 'Connected to server'})


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
    emit('disconnected', {'status': 'Disconnected from server'})


@socketio.on('start_session')
def handle_start_session(data):
    session_id = request.sid
    video_mode = data.get('mode', DEFAULT_MODE)
    
    if session_id in active_sessions:
        active_sessions[session_id].stop()
    
    audio_loop = AudioLoop(video_mode=video_mode, session_id=session_id)
    active_sessions[session_id] = audio_loop
    
    def run_async():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(audio_loop.run())
    
    thread = Thread(target=run_async, daemon=True)
    thread.start()
    
    emit('session_started', {'status': 'Session started', 'mode': video_mode})


@socketio.on('stop_session')
def handle_stop_session():
    session_id = request.sid
    if session_id in active_sessions:
        active_sessions[session_id].stop()
        del active_sessions[session_id]
        emit('session_stopped', {'status': 'Session stopped'})


@socketio.on('send_message')
def handle_message(data):
    session_id = request.sid
    text = data.get('text', '')
    
    if session_id in active_sessions:
        audio_loop = active_sessions[session_id]
        
        if audio_loop.event_loop and audio_loop.event_loop.is_running():
            # Use the existing event loop
            asyncio.run_coroutine_threadsafe(
                audio_loop.send_text_message(text),
                audio_loop.event_loop
            )
        else:
            # Fallback: create new event loop
            def send_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(audio_loop.send_text_message(text))
            
            thread = Thread(target=send_async, daemon=True)
            thread.start()
        
        emit('message_sent', {'status': 'Message sent'})


if __name__ == '__main__':
    # Use port 5001 by default to avoid conflict with macOS AirPlay Receiver on port 5000
    port = int(os.getenv('FLASK_PORT', 5001))
    print(f"\nüöÄ Starting Flask server on http://localhost:{port}")
    print(f"üìù Open your browser and navigate to: http://localhost:{port}\n")
    socketio.run(app, debug=True, host='0.0.0.0', port=port)


```

```plaintext
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>NSCameraUsageDescription</key>
    <string>This app needs camera access to stream video to Gemini Live API</string>
    <key>NSMicrophoneUsageDescription</key>
    <string>This app needs microphone access to stream audio to Gemini Live API</string>
    <key>NSCameraUseContinuityCameraDeviceType</key>
    <true/>
</dict>
</plist>

```

Adding cache-busting to the HTML and updating the README with Info.plist details:


```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <title>Gemini Live API - Flask UI</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .controls {
            padding: 30px;
            background: #f8f9fa;
            border-bottom: 1px solid #e0e0e0;
        }

        .control-group {
            display: flex;
            gap: 15px;
            align-items: center;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }

        .control-group label {
            font-weight: 600;
            color: #333;
        }

        .mode-selector {
            display: flex;
            gap: 10px;
        }

        .mode-btn {
            padding: 10px 20px;
            border: 2px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s;
        }

        .mode-btn:hover {
            background: #667eea;
            color: white;
        }

        .mode-btn.active {
            background: #667eea;
            color: white;
        }

        .action-btn {
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-start {
            background: #10b981;
            color: white;
        }

        .btn-start:hover {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }

        .btn-stop {
            background: #ef4444;
            color: white;
        }

        .btn-stop:hover {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }

        .btn-stop:disabled,
        .btn-start:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .content {
            padding: 30px;
        }

        .message-section {
            margin-bottom: 30px;
        }

        .message-section h2 {
            margin-bottom: 15px;
            color: #333;
        }

        .message-input-group {
            display: flex;
            gap: 10px;
        }

        .message-input {
            flex: 1;
            padding: 12px 15px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 1em;
            transition: border-color 0.3s;
        }

        .message-input:focus {
            outline: none;
            border-color: #667eea;
        }

        .btn-send {
            padding: 12px 25px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-send:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .btn-send:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .response-area {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }

        .response-text {
            color: #333;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .status {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .status.connected {
            background: #d1fae5;
            color: #065f46;
        }

        .status.disconnected {
            background: #fee2e2;
            color: #991b1b;
        }

        .status.info {
            background: #dbeafe;
            color: #1e40af;
        }

        .audio-player {
            margin-top: 20px;
            padding: 15px;
            background: #f0f0f0;
            border-radius: 8px;
            text-align: center;
        }

        audio {
            width: 100%;
            max-width: 500px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Gemini Live API</h1>
            <p>Real-time audio and video interaction with Google Gemini</p>
        </div>

        <div class="controls">
            <div class="control-group">
                <label>Video Mode:</label>
                <div class="mode-selector">
                    <button class="mode-btn active" data-mode="camera">üì∑ Camera</button>
                    <button class="mode-btn" data-mode="screen">üñ•Ô∏è Screen</button>
                    <button class="mode-btn" data-mode="none">üö´ None</button>
                </div>
            </div>
            <div class="control-group">
                <button id="startBtn" class="action-btn btn-start">‚ñ∂Ô∏è Start Session</button>
                <button id="stopBtn" class="action-btn btn-stop" disabled>‚èπÔ∏è Stop Session</button>
            </div>
        </div>

        <div class="content">
            <div id="status" class="status disconnected">Disconnected</div>

            <div class="message-section">
                <h2>üí¨ Send Message</h2>
                <div class="message-input-group">
                    <input type="text" id="messageInput" class="message-input" placeholder="Type your message here..." disabled>
                    <button id="sendBtn" class="btn-send" disabled>Send</button>
                </div>
            </div>

            <div class="message-section">
                <h2>üìù Response</h2>
                <div class="response-area">
                    <div id="responseText" class="response-text">Waiting for response...</div>
                </div>
            </div>

            <div class="audio-player" id="audioPlayer" style="display: none;">
                <h3>üîä Audio Response</h3>
                <audio id="audioElement" controls></audio>
            </div>
        </div>
    </div>

    <script>
        const socket = io();
        let currentMode = 'camera';
        let sessionActive = false;

        // Status updates
        socket.on('connect', () => {
            updateStatus('Connected to server', 'connected');
        });

        socket.on('disconnect', () => {
            updateStatus('Disconnected from server', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('connected', (data) => {
            updateStatus('Connected: ' + data.status, 'connected');
        });

        socket.on('session_started', (data) => {
            updateStatus(`Session started in ${data.mode} mode`, 'info');
            sessionActive = true;
            updateUI();
        });

        socket.on('session_stopped', (data) => {
            updateStatus('Session stopped', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('text_response', (data) => {
            const responseText = document.getElementById('responseText');
            responseText.textContent += data.text;
        });

        socket.on('audio_data', (data) => {
            // Handle audio data if needed
            // Note: Browser audio playback from PCM data requires Web Audio API
            console.log('Audio data received');
        });

        socket.on('error', (data) => {
            // Only show alerts for critical errors, not for disabled features
            if (data.message.includes('not available') || data.message.includes('disabled')) {
                updateStatus('Info: ' + data.message, 'info');
            } else {
                updateStatus('Error: ' + data.message, 'disconnected');
                alert('Error: ' + data.message);
            }
        });

        socket.on('info', (data) => {
            updateStatus('Info: ' + data.message, 'info');
        });

        // Mode selection
        document.querySelectorAll('.mode-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.mode-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentMode = btn.dataset.mode;
            });
        });

        // Start/Stop buttons
        document.getElementById('startBtn').addEventListener('click', () => {
            socket.emit('start_session', { mode: currentMode });
        });

        document.getElementById('stopBtn').addEventListener('click', () => {
            socket.emit('stop_session');
            document.getElementById('responseText').textContent = 'Waiting for response...';
        });

        // Send message
        document.getElementById('sendBtn').addEventListener('click', () => {
            const input = document.getElementById('messageInput');
            const text = input.value.trim();
            if (text) {
                socket.emit('send_message', { text: text });
                input.value = '';
            }
        });

        document.getElementById('messageInput').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                document.getElementById('sendBtn').click();
            }
        });

        function updateStatus(message, type) {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status ' + type;
        }

        function updateUI() {
            const startBtn = document.getElementById('startBtn');
            const stopBtn = document.getElementById('stopBtn');
            const messageInput = document.getElementById('messageInput');
            const sendBtn = document.getElementById('sendBtn');

            if (sessionActive) {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                messageInput.disabled = false;
                sendBtn.disabled = false;
            } else {
                startBtn.disabled = false;
                stopBtn.disabled = true;
                messageInput.disabled = true;
                sendBtn.disabled = true;
            }
        }
    </script>
</body>
</html>


```

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <title>Gemini Live API - Flask UI</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .controls {
            padding: 30px;
            background: #f8f9fa;
            border-bottom: 1px solid #e0e0e0;
        }

        .control-group {
            display: flex;
            gap: 15px;
            align-items: center;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }

        .control-group label {
            font-weight: 600;
            color: #333;
        }

        .mode-selector {
            display: flex;
            gap: 10px;
        }

        .mode-btn {
            padding: 10px 20px;
            border: 2px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s;
        }

        .mode-btn:hover {
            background: #667eea;
            color: white;
        }

        .mode-btn.active {
            background: #667eea;
            color: white;
        }

        .action-btn {
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-start {
            background: #10b981;
            color: white;
        }

        .btn-start:hover {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }

        .btn-stop {
            background: #ef4444;
            color: white;
        }

        .btn-stop:hover {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }

        .btn-stop:disabled,
        .btn-start:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .content {
            padding: 30px;
        }

        .message-section {
            margin-bottom: 30px;
        }

        .message-section h2 {
            margin-bottom: 15px;
            color: #333;
        }

        .message-input-group {
            display: flex;
            gap: 10px;
        }

        .message-input {
            flex: 1;
            padding: 12px 15px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 1em;
            transition: border-color 0.3s;
        }

        .message-input:focus {
            outline: none;
            border-color: #667eea;
        }

        .btn-send {
            padding: 12px 25px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-send:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .btn-send:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .response-area {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }

        .response-text {
            color: #333;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .status {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .status.connected {
            background: #d1fae5;
            color: #065f46;
        }

        .status.disconnected {
            background: #fee2e2;
            color: #991b1b;
        }

        .status.info {
            background: #dbeafe;
            color: #1e40af;
        }

        .audio-player {
            margin-top: 20px;
            padding: 15px;
            background: #f0f0f0;
            border-radius: 8px;
            text-align: center;
        }

        audio {
            width: 100%;
            max-width: 500px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Gemini Live API</h1>
            <p>Real-time audio and video interaction with Google Gemini</p>
        </div>

        <div class="controls">
            <div class="control-group">
                <label>Video Mode:</label>
                <div class="mode-selector">
                    <button class="mode-btn active" data-mode="camera">üì∑ Camera</button>
                    <button class="mode-btn" data-mode="screen">üñ•Ô∏è Screen</button>
                    <button class="mode-btn" data-mode="none">üö´ None</button>
                </div>
            </div>
            <div class="control-group">
                <button id="startBtn" class="action-btn btn-start">‚ñ∂Ô∏è Start Session</button>
                <button id="stopBtn" class="action-btn btn-stop" disabled>‚èπÔ∏è Stop Session</button>
            </div>
        </div>

        <div class="content">
            <div id="status" class="status disconnected">Disconnected</div>

            <div class="message-section">
                <h2>üí¨ Send Message</h2>
                <div class="message-input-group">
                    <input type="text" id="messageInput" class="message-input" placeholder="Type your message here..." disabled>
                    <button id="sendBtn" class="btn-send" disabled>Send</button>
                </div>
            </div>

            <div class="message-section">
                <h2>üìù Response</h2>
                <div class="response-area">
                    <div id="responseText" class="response-text">Waiting for response...</div>
                </div>
            </div>

            <div class="audio-player" id="audioPlayer" style="display: none;">
                <h3>üîä Audio Response</h3>
                <audio id="audioElement" controls></audio>
            </div>
        </div>
    </div>

    <script>
        const socket = io();
        let currentMode = 'camera';
        let sessionActive = false;

        // Status updates
        socket.on('connect', () => {
            updateStatus('Connected to server', 'connected');
        });

        socket.on('disconnect', () => {
            updateStatus('Disconnected from server', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('connected', (data) => {
            updateStatus('Connected: ' + data.status, 'connected');
        });

        socket.on('session_started', (data) => {
            updateStatus(`Session started in ${data.mode} mode`, 'info');
            sessionActive = true;
            updateUI();
        });

        socket.on('session_stopped', (data) => {
            updateStatus('Session stopped', 'disconnected');
            sessionActive = false;
            updateUI();
        });

        socket.on('text_response', (data) => {
            const responseText = document.getElementById('responseText');
            responseText.textContent += data.text;
        });

        socket.on('audio_data', (data) => {
            // Handle audio data if needed
            // Note: Browser audio playback from PCM data requires Web Audio API
            console.log('Audio data received');
        });

        socket.on('error', (data) => {
            // Only show alerts for critical errors, not for disabled features
            const msg = data.message || '';
            if (msg.includes('not available') || 
                msg.includes('disabled') || 
                msg.includes('PyAudio') ||
                msg.includes('Audio output') ||
                msg.includes('Audio input') ||
                msg.includes('Camera') ||
                msg.includes('Text-only')) {
                updateStatus('Info: ' + msg, 'info');
            } else {
                updateStatus('Error: ' + msg, 'disconnected');
                alert('Error: ' + msg);
            }
        });

        socket.on('info', (data) => {
            updateStatus('Info: ' + data.message, 'info');
        });

        // Mode selection
        document.querySelectorAll('.mode-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.mode-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentMode = btn.dataset.mode;
            });
        });

        // Start/Stop buttons
        document.getElementById('startBtn').addEventListener('click', () => {
            socket.emit('start_session', { mode: currentMode });
        });

        document.getElementById('stopBtn').addEventListener('click', () => {
            socket.emit('stop_session');
            document.getElementById('responseText').textContent = 'Waiting for response...';
        });

        // Send message
        document.getElementById('sendBtn').addEventListener('click', () => {
            const input = document.getElementById('messageInput');
            const text = input.value.trim();
            if (text) {
                socket.emit('send_message', { text: text });
                input.value = '';
            }
        });

        document.getElementById('messageInput').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                document.getElementById('sendBtn').click();
            }
        });

        function updateStatus(message, type) {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status ' + type;
        }

        function updateUI() {
            const startBtn = document.getElementById('startBtn');
            const stopBtn = document.getElementById('stopBtn');
            const messageInput = document.getElementById('messageInput');
            const sendBtn = document.getElementById('sendBtn');

            if (sessionActive) {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                messageInput.disabled = false;
                sendBtn.disabled = false;
            } else {
                startBtn.disabled = false;
                stopBtn.disabled = true;
                messageInput.disabled = true;
                sendBtn.disabled = true;
            }
        }
    </script>
</body>
</html>


```

Updating the README with Info.plist details:


```markdown
# Gemini Live API - Flask UI

A Flask web interface for Google Gemini Live API with real-time audio and video streaming capabilities.

## Features

- üéôÔ∏è Real-time audio input/output
- üì∑ Camera video streaming
- üñ•Ô∏è Screen sharing support
- üí¨ Text message interface
- üåê Modern web UI

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. **Fix PyAudio on macOS (if needed):**
   If you encounter PyAudio import errors, PortAudio needs to be installed:
   ```bash
   brew install portaudio
   pip uninstall pyaudio
   pip install pyaudio
   ```
   Or run the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

3. Ensure your `.env` file contains:
```
GOOGLE_API_KEY=your_api_key_here
```

4. Run the Flask application:
```bash
python app.py
```

5. Open your browser and navigate to:
```
http://localhost:5001
```

**Note:** The app uses port 5001 by default to avoid conflicts with macOS AirPlay Receiver (which uses port 5000). You can change the port by setting the `FLASK_PORT` environment variable:
```bash
FLASK_PORT=8080 python app.py
```

## Usage

1. Select your preferred video mode:
   - **Camera**: Stream from your webcam
   - **Screen**: Share your screen
   - **None**: Audio only

2. Click **Start Session** to begin

3. Type messages in the input field and click **Send** or press Enter

4. View responses in the response area

5. Click **Stop Session** when done

## Troubleshooting

### PyAudio Import Errors on macOS

If you see errors like `symbol not found in flat namespace '_PaMacCore_SetupChannelMap'`:

1. Install PortAudio via Homebrew:
   ```bash
   brew install portaudio
   ```

2. Reinstall PyAudio:
   ```bash
   pip uninstall pyaudio
   pip install pyaudio
   ```

3. Or use the provided fix script:
   ```bash
   ./fix_pyaudio.sh
   ```

The app will still run without PyAudio, but audio features will be disabled.

### Port Already in Use

If you see "Address already in use" or "Port 5000 is in use":
- The app now defaults to port 5001 to avoid macOS AirPlay Receiver conflicts
- To use a different port, set `FLASK_PORT` environment variable:
  ```bash
  FLASK_PORT=8080 python app.py
  ```
- Or disable AirPlay Receiver: System Preferences ‚Üí General ‚Üí AirDrop & Handoff ‚Üí AirPlay Receiver

### macOS Camera Deprecation Warning

If you see a warning about `AVCaptureDeviceTypeExternal` being deprecated:
- This is a harmless macOS system warning from OpenCV
- The app includes code to suppress this warning automatically
- The warning does not affect functionality
- An `Info.plist` file is included for reference, but it's not used when running Flask from Python directly
- If you bundle the app as a macOS application, you would include the Info.plist in the app bundle

## Important Notes

- **Use headphones** to prevent audio feedback
- The application uses your system's default audio input/output devices
- Camera and screen sharing require appropriate permissions
- If PyAudio is not available, the app will run but audio features will be disabled

## Original Script

The original command-line script (`main.py`) is still available for direct use.


```

Made updates to address both issues:

## Changes Made:

1. **Suppressed macOS camera deprecation warning** ‚Äî Added code to suppress the `AVCaptureDeviceTypeExternal` warning from OpenCV.

2. **Created Info.plist file** ‚Äî Added `Info.plist` with camera and microphone usage descriptions. Note: This file is for reference; Flask apps running from Python don't use it. It's useful if you bundle the app as a macOS application.

3. **Improved error handling** ‚Äî Updated the frontend to treat PyAudio/camera availability messages as info, not errors, and prevent alert popups.

4. **Added cache-busting** ‚Äî Added meta tags to prevent browser caching of the HTML.

5. **Updated README** ‚Äî Added a section explaining the macOS camera warning.

## To Fix the Error You're Seeing:

1. Restart the Flask app ‚Äî Stop and restart `python app.py` to load the warning suppression code.

2. Hard refresh your browser ‚Äî Press `Cmd+Shift+R` (Mac) or `Ctrl+Shift+R` (Windows/Linux) to clear the cache and reload the page.

3. The messages should now appear as blue info messages instead of red error alerts.

The app should now:
- Suppress the macOS camera deprecation warning
- Show PyAudio/camera messages as informational (not errors)
- Work in text-only mode even without audio/video

If you still see error alerts after restarting and hard refreshing, let me know and I can investigate further.

